# -*- coding: utf-8 -*-
"""flipkart.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TMkXYbOvcX60lwi8wBbCQ0kP_oNZNYVt
"""

from google.colab import files
uploaded=files.upload()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score, classification_report
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
from nltk.tokenize import word_tokenize
from wordcloud import WordCloud

!pip install vaderSentiment

from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
import warnings
warnings.filterwarnings('ignore')

# Load the dataset
df = pd.read_csv('flipkart.csv')

# Check for null values
print(df.isnull().sum())

# Handle null values (e.g., drop or fill)
df.dropna(inplace=True)  # or use df.fillna() if appropriate

df.shape

df.columns

# Plot ratings distribution
plt.figure(figsize=(8, 6))
df['Rating'].value_counts().plot(kind='pie', autopct='%1.1f%%')
plt.title('Product Ratings Distribution')
plt.ylabel('')
plt.show()

import re
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
import nltk
nltk.download('punkt')

# Initialize stemmer and stopwords
stemmer = PorterStemmer()
stop_words = set(stopwords.words('english'))

# Function to clean text
def clean_text(text):
    text = text.lower()
    text = re.sub(r'\d+', '', text)
    text = re.sub(r'[^\w\s]', '', text)
    words = word_tokenize(text)
    words = [stemmer.stem(word) for word in words if word not in stop_words]
    return ' '.join(words)

df['cleaned_reviews'] = df['Review'].apply(clean_text)

# Generate WordCloud
text = ' '.join(df['cleaned_reviews'])
wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)

plt.figure(figsize=(10, 5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.show()

# Initialize sentiment analyzer
analyzer = SentimentIntensityAnalyzer()

# Function to get sentiment
def get_sentiment(text):
    score = analyzer.polarity_scores(text)
    return score

# Apply sentiment analysis
df['sentiment'] = df['cleaned_reviews'].apply(get_sentiment)
df['positive'] = df['sentiment'].apply(lambda x: x['pos'])
df['negative'] = df['sentiment'].apply(lambda x: x['neg'])
df['neutral'] = df['sentiment'].apply(lambda x: x['neu'])

# Calculate overall sentiment scores
overall_sentiment = df[['positive', 'negative', 'neutral']].mean()
print("Overall Sentiment Scores:")
print(overall_sentiment)